{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vayshu08/NLP/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "def train_bigram_model(corpus):\n",
        "    # Tokenize the corpus into words\n",
        "    tokens = corpus.split()\n",
        "\n",
        "    # Create a list of tuples where each tuple is a bigram (word_i, word_i+1)\n",
        "    bigrams = list(zip(tokens[:-1], tokens[1:]))\n",
        "\n",
        "    # Create a dictionary to store the bigram frequencies\n",
        "    bigram_freq = defaultdict(Counter)\n",
        "\n",
        "    # Count occurrences of each bigram\n",
        "    for prev_word, next_word in bigrams:\n",
        "        bigram_freq[prev_word][next_word] += 1\n",
        "\n",
        "    # Convert frequencies into probabilities\n",
        "    bigram_model = defaultdict(dict)\n",
        "    for prev_word, next_words in bigram_freq.items():\n",
        "        total_count = sum(next_words.values())\n",
        "        for next_word, count in next_words.items():\n",
        "            bigram_model[prev_word][next_word] = count / total_count\n",
        "\n",
        "    return bigram_model\n",
        "\n",
        "def generate_text(bigram_model, seed_word, max_length=20):\n",
        "    current_word = seed_word\n",
        "    text = [current_word]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        if current_word in bigram_model:\n",
        "            next_word_candidates = list(bigram_model[current_word].keys())\n",
        "            next_word_probs = list(bigram_model[current_word].values())\n",
        "            current_word = random.choices(next_word_candidates, weights=next_word_probs)[0]\n",
        "            text.append(current_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(text)\n",
        "\n",
        "# Example usage:\n",
        "corpus = \"this is a simple example of a corpus for bigram model implementation\"\n",
        "bigram_model = train_bigram_model(corpus)\n",
        "\n",
        "# Print the trained bigram model\n",
        "print(\"Bigram Model:\")\n",
        "for prev_word, next_words in bigram_model.items():\n",
        "    for next_word, prob in next_words.items():\n",
        "        print(f'P({next_word} | {prev_word}) = {prob:.4f}')\n",
        "\n",
        "# Generate text using the bigram model\n",
        "seed_word = \"this\"\n",
        "generated_text = generate_text(bigram_model, seed_word)\n",
        "print(f\"\\nGenerated Text starting with '{seed_word}':\\n{generated_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2bLqfRNzg7Z",
        "outputId": "a2bd1494-a457-4456-8d77-036a80736825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Model:\n",
            "P(is | this) = 1.0000\n",
            "P(a | is) = 1.0000\n",
            "P(simple | a) = 0.5000\n",
            "P(corpus | a) = 0.5000\n",
            "P(example | simple) = 1.0000\n",
            "P(of | example) = 1.0000\n",
            "P(a | of) = 1.0000\n",
            "P(for | corpus) = 1.0000\n",
            "P(bigram | for) = 1.0000\n",
            "P(model | bigram) = 1.0000\n",
            "P(implementation | model) = 1.0000\n",
            "\n",
            "Generated Text starting with 'this':\n",
            "this is a corpus for bigram model implementation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "def compute_bigram_probabilities(corpus):\n",
        "    # Tokenize the corpus into words\n",
        "    tokens = corpus.split()\n",
        "\n",
        "    # Create a list of bigrams (word_i, word_i+1)\n",
        "    bigrams = list(zip(tokens[:-1], tokens[1:]))\n",
        "\n",
        "    # Count occurrences of each bigram\n",
        "    bigram_counts = Counter(bigrams)\n",
        "\n",
        "    # Compute probabilities\n",
        "    bigram_probabilities = defaultdict(dict)\n",
        "    total_bigrams = len(bigrams)\n",
        "\n",
        "    for bigram, count in bigram_counts.items():\n",
        "        prev_word, next_word = bigram\n",
        "        bigram_probabilities[prev_word][next_word] = count / total_bigrams\n",
        "\n",
        "    return bigram_probabilities\n",
        "\n",
        "# Example usage:\n",
        "corpus = \"this is a simple example of a corpus for bigram probabilities computation\"\n",
        "bigram_probabilities = compute_bigram_probabilities(corpus)\n",
        "\n",
        "# Print the computed bigram probabilities\n",
        "print(\"Bigram Probabilities:\")\n",
        "for prev_word, next_words in bigram_probabilities.items():\n",
        "    for next_word, prob in next_words.items():\n",
        "        print(f'P({next_word} | {prev_word}) = {prob:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaV1KDKD0bb5",
        "outputId": "a892d0bb-6a85-4fa2-ae87-62138e0a5dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Probabilities:\n",
            "P(is | this) = 0.0909\n",
            "P(a | is) = 0.0909\n",
            "P(simple | a) = 0.0909\n",
            "P(corpus | a) = 0.0909\n",
            "P(example | simple) = 0.0909\n",
            "P(of | example) = 0.0909\n",
            "P(a | of) = 0.0909\n",
            "P(for | corpus) = 0.0909\n",
            "P(bigram | for) = 0.0909\n",
            "P(probabilities | bigram) = 0.0909\n",
            "P(computation | probabilities) = 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HifUdBzhzUWa",
        "outputId": "ea84556a-9633-40a9-98db-a64faee80d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Model:\n",
            "P(this) = 0.0909\n",
            "P(is) = 0.0909\n",
            "P(a) = 0.1818\n",
            "P(simple) = 0.0909\n",
            "P(example) = 0.0909\n",
            "P(of) = 0.0909\n",
            "P(corpus) = 0.0909\n",
            "P(for) = 0.0909\n",
            "P(unigram) = 0.0909\n",
            "P(model) = 0.0909\n",
            "\n",
            "Probability of 'example': 0.0909\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def train_unigram_model(corpus):\n",
        "    # Tokenize the corpus into words\n",
        "    tokens = corpus.split()\n",
        "\n",
        "    # Count occurrences of each word\n",
        "    word_counts = Counter(tokens)\n",
        "\n",
        "    # Total number of words in the corpus\n",
        "    total_words = len(tokens)\n",
        "\n",
        "    # Calculate probabilities for each word\n",
        "    unigram_model = {word: count / total_words for word, count in word_counts.items()}\n",
        "\n",
        "    return unigram_model\n",
        "\n",
        "def get_word_probability(unigram_model, word):\n",
        "    # Get the probability of a single word\n",
        "    return unigram_model.get(word, 0)\n",
        "\n",
        "# Example usage:\n",
        "corpus = \"this is a simple example of a corpus for unigram model\"\n",
        "unigram_model = train_unigram_model(corpus)\n",
        "\n",
        "# Print the trained unigram model\n",
        "print(\"Unigram Model:\")\n",
        "for word, prob in unigram_model.items():\n",
        "    print(f'P({word}) = {prob:.4f}')\n",
        "\n",
        "# Calculate probability of a specific word\n",
        "word_to_check = \"example\"\n",
        "prob_example = get_word_probability(unigram_model, word_to_check)\n",
        "print(f\"\\nProbability of '{word_to_check}': {prob_example:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_trigrams(text):\n",
        "    words = text.split()\n",
        "    trigrams = {}\n",
        "\n",
        "    for i in range(len(words) - 2):\n",
        "        key = (words[i], words[i + 1])\n",
        "        value = words[i + 2]\n",
        "        if key in trigrams:\n",
        "            trigrams[key].append(value)\n",
        "        else:\n",
        "            trigrams[key] = [value]\n",
        "\n",
        "    return trigrams\n",
        "\n",
        "def generate_text(trigrams, length=50):\n",
        "    start = list(trigrams.keys())[0]  # start with the first trigram in the text\n",
        "    text = list(start)\n",
        "\n",
        "    while len(text) < length:\n",
        "        last_two_words = tuple(text[-2:])\n",
        "        if last_two_words in trigrams:\n",
        "            next_word = trigrams[last_two_words][0]  # choose the first word from the list of possible next words\n",
        "            text.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(text)\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == '__main__':\n",
        "    text = \"A trigram is a sequence of three consecutive words in a text. This is an example of a trigram generator.\"\n",
        "    trigrams = generate_trigrams(text)\n",
        "    generated_text = generate_text(trigrams)\n",
        "    print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOIK3dTV1wwy",
        "outputId": "43b8e86e-ae44-4ec6-9097-d1c3f5a4cab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A trigram is a sequence of three consecutive words in a text. This is an example of a trigram generator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class WordPredictor:\n",
        "    def __init__(self, n_gram=2):\n",
        "        self.n_gram = n_gram\n",
        "        self.n_grams = defaultdict(list)\n",
        "\n",
        "    def train(self, text):\n",
        "        words = text.split()\n",
        "        for i in range(len(words) - self.n_gram):\n",
        "            n_gram_tuple = tuple(words[i:i + self.n_gram])\n",
        "            next_word = words[i + self.n_gram]\n",
        "            self.n_grams[n_gram_tuple].append(next_word)\n",
        "\n",
        "    def predict_next_word(self, text):\n",
        "        words = text.split()\n",
        "        n = len(words)\n",
        "\n",
        "        if n < self.n_gram:\n",
        "            return \"Not enough words to predict\"\n",
        "\n",
        "        n_gram_prefix = tuple(words[-self.n_gram:])\n",
        "\n",
        "        if n_gram_prefix in self.n_grams:\n",
        "            next_words = self.n_grams[n_gram_prefix]\n",
        "            return random.choice(next_words)\n",
        "        else:\n",
        "            return \"No prediction available\"\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == '__main__':\n",
        "    predictor = WordPredictor(n_gram=2)\n",
        "\n",
        "    # Example text for training\n",
        "    text = \"Natural language processing is a subfield of artificial intelligence.\"\n",
        "    predictor.train(text)\n",
        "\n",
        "    # Example of predicting the next word\n",
        "    input_text = \"Natural language processing\"\n",
        "    predicted_word = predictor.predict_next_word(input_text)\n",
        "    print(f\"Input text: '{input_text}'\")\n",
        "    print(f\"Predicted next word: {predicted_word}\")\n"
      ],
      "metadata": {
        "id": "TcHP-2nQ16qx",
        "outputId": "ff4b0cbd-1d7a-4d22-9e16-2476421eeab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: 'Natural language processing'\n",
            "Predicted next word: is\n"
          ]
        }
      ]
    }
  ]
}